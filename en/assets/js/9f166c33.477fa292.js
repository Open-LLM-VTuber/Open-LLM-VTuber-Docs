"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[40],{8656:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>r});const s=JSON.parse('{"id":"user-guide/backend/tts","title":"Speech Synthesis (TTS)","description":"After installing the required dependencies and configuring conf.yaml, enable the corresponding speech synthesis engine by modifying the TTS_MODEL option in conf.yaml.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/user-guide/backend/tts.md","sourceDirName":"user-guide/backend","slug":"/user-guide/backend/tts","permalink":"/en/docs/user-guide/backend/tts","draft":false,"unlisted":false,"editUrl":"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Docs/tree/main/docs/user-guide/backend/tts.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"docSidebar","previous":{"title":"Agent","permalink":"/en/docs/user-guide/backend/agent"},"next":{"title":"Translation","permalink":"/en/docs/user-guide/backend/translate"}}');var l=i(4848),t=i(8453);const o={sidebar_position:6},d="Speech Synthesis (TTS)",c={},r=[{value:"sherpa-onnx (Local &amp; Recommended)",id:"sherpa-onnx-local--recommended",level:2},{value:"pyttsx3 (Lightweight and Fast)",id:"pyttsx3-lightweight-and-fast",level:2},{value:"MeloTTS (Local Deployment)",id:"melotts-local-deployment",level:2},{value:"Installation Steps",id:"installation-steps",level:3},{value:"Additional Notes",id:"additional-notes",level:3},{value:"Coqui-TTS (Local Deployment)",id:"coqui-tts-local-deployment",level:2},{value:"Installation Steps",id:"installation-steps-1",level:3},{value:"Model Configuration",id:"model-configuration",level:3},{value:"GPTSoVITS (Local Deployment, Moderate Performance)",id:"gptsovits-local-deployment-moderate-performance",level:2},{value:"GPTSoVITS-V2 Integration Package",id:"gptsovits-v2-integration-package",level:3},{value:"miHoYo One-Click Package",id:"mihoyo-one-click-package",level:3},{value:"Bark (Local Deployment, Relatively Slow)",id:"bark-local-deployment-relatively-slow",level:2},{value:"CosyVoice TTS (Local Deployment, Relatively Slow)",id:"cosyvoice-tts-local-deployment-relatively-slow",level:2},{value:"X-TTS (Local Deployment, Relatively Slow)",id:"x-tts-local-deployment-relatively-slow",level:4},{value:"Edge TTS (Online, No API Key Required)",id:"edge-tts-online-no-api-key-required",level:2},{value:"Fish Audio TTS (Online, API Key Required)",id:"fish-audio-tts-online-api-key-required",level:4},{value:"Azure TTS (Online, API Key Required)",id:"azure-tts-online-api-key-required",level:3}];function a(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"speech-synthesis-tts",children:"Speech Synthesis (TTS)"})}),"\n",(0,l.jsxs)(n.p,{children:["After installing the required dependencies and configuring ",(0,l.jsx)(n.code,{children:"conf.yaml"}),", enable the corresponding speech synthesis engine by modifying the ",(0,l.jsx)(n.code,{children:"TTS_MODEL"})," option in ",(0,l.jsx)(n.code,{children:"conf.yaml"}),"."]}),"\n",(0,l.jsx)(n.h2,{id:"sherpa-onnx-local--recommended",children:"sherpa-onnx (Local & Recommended)"}),"\n",(0,l.jsxs)(n.blockquote,{children:["\n",(0,l.jsxs)(n.p,{children:["Available since version ",(0,l.jsx)(n.code,{children:"v0.5.0-alpha.1"})," (",(0,l.jsx)(n.a,{href:"https://github.com/t41372/Open-LLM-VTuber/pull/50",children:"PR#50"}),")"]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"sherpa-onnx is a powerful inference engine that supports multiple TTS models (including MeloTTS). It is built-in supported and uses CPU inference by default."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Configuration Steps:"})}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Download the required model from ",(0,l.jsx)(n.a,{href:"https://github.com/k2-fsa/sherpa-onnx/releases/tag/tts-models",children:"sherpa-onnx TTS models"})]}),"\n",(0,l.jsxs)(n.li,{children:["Modify ",(0,l.jsx)(n.code,{children:"conf.yaml"})," referring to the configuration examples in ",(0,l.jsx)(n.code,{children:"config_alts"})]}),"\n"]}),"\n",(0,l.jsx)(n.admonition,{type:"tip",children:(0,l.jsxs)(n.p,{children:["For GPU inference (CUDA only), please refer to ",(0,l.jsx)(n.a,{href:"/docs/user-guide/backend/asr#cuda-inference",children:"CUDA Inference"}),"."]})}),"\n",(0,l.jsx)(n.h2,{id:"pyttsx3-lightweight-and-fast",children:"pyttsx3 (Lightweight and Fast)"}),"\n",(0,l.jsxs)(n.p,{children:["A simple and easy-to-use local TTS engine that uses the system's default speech synthesizer. We use ",(0,l.jsx)(n.code,{children:"py3-tts"})," instead of the more famous ",(0,l.jsx)(n.code,{children:"pyttsx3"})," because ",(0,l.jsx)(n.code,{children:"pyttsx3"})," seems unmaintained and failed to run on the test computer."]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Configuration Steps:"})}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Install by running ",(0,l.jsx)(n.code,{children:"uv pip install py3-tts"})]}),"\n",(0,l.jsxs)(n.li,{children:["Set ",(0,l.jsx)(n.code,{children:"tts_model: pyttsx3_tts"})," in ",(0,l.jsx)(n.code,{children:"conf.yaml"})]}),"\n"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Install using the command ",(0,l.jsx)(n.code,{children:"uv pip install py3-tts"}),"."]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.ol,{start:"2",children:["\n",(0,l.jsxs)(n.li,{children:["This TTS engine has no configuration options, simply set ",(0,l.jsx)(n.code,{children:"tts_model: pyttsx3_tts"})," in ",(0,l.jsx)(n.code,{children:"conf.yaml"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.admonition,{type:"info",children:[(0,l.jsx)(n.p,{children:"This package will use the default TTS engine on your system:"}),(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Windows uses the sapi5 engine"}),"\n",(0,l.jsx)(n.li,{children:"macOS uses the nsss engine"}),"\n",(0,l.jsx)(n.li,{children:"Other platforms use the espeak engine"}),"\n"]})]}),"\n",(0,l.jsx)(n.h2,{id:"melotts-local-deployment",children:"MeloTTS (Local Deployment)"}),"\n",(0,l.jsx)(n.admonition,{title:"Important Note",type:"warning",children:(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"It is strongly recommended to use MeloTTS through sherpa-onnx, rather than installing the more complex official version"}),"\n",(0,l.jsx)(n.li,{children:"MeloTTS has dependency conflicts with Coqui-TTS, please do not install them simultaneously"}),"\n",(0,l.jsx)(n.li,{children:"The official version of MeloTTS may encounter mps-related errors on macOS (solutions are welcome)"}),"\n"]})}),"\n",(0,l.jsx)(n.h3,{id:"installation-steps",children:"Installation Steps"}),"\n",(0,l.jsxs)(n.blockquote,{children:["\n",(0,l.jsxs)(n.p,{children:["Starting from project version ",(0,l.jsx)(n.code,{children:"v1.0.0"}),", we use ",(0,l.jsx)(n.code,{children:"uv"})," to manage dependencies, which greatly simplifies the installation process of MeloTTS."]}),"\n"]}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Install MeloTTS and necessary components:"}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sh",children:"# Install MeloTTS\nuv add git+https://github.com/myshell-ai/MeloTTS.git\n\n# Download unidic\npython -m unidic download\n"})}),"\n",(0,l.jsxs)(n.ol,{start:"2",children:["\n",(0,l.jsx)(n.li,{children:"Download additional dependencies:"}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sh",children:"# Enter Python interpreter\npython\n\n# Download necessary NLTK data\n>>> import nltk\n>>> nltk.download('averaged_perceptron_tagger_eng')\n# Press Ctrl+D to exit the interpreter when finished\n"})}),"\n",(0,l.jsxs)(n.ol,{start:"3",children:["\n",(0,l.jsx)(n.li,{children:"Configure and enable:"}),"\n"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Edit the project's ",(0,l.jsx)(n.code,{children:"conf.yaml"})," file"]}),"\n",(0,l.jsxs)(n.li,{children:["Set ",(0,l.jsx)(n.code,{children:"tts_model"})," to ",(0,l.jsx)(n.code,{children:"melo_tts"})]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"additional-notes",children:"Additional Notes"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Official documentation: ",(0,l.jsx)(n.a,{href:"https://github.com/myshell-ai/MeloTTS/blob/main/docs/install.md",children:"MeloTTS Installation Guide"})]}),"\n",(0,l.jsxs)(n.li,{children:["If encountering ",(0,l.jsx)(n.code,{children:"mecab-python"})," related issues, try using this ",(0,l.jsx)(n.a,{href:"https://github.com/polm/MeloTTS",children:"branch"})," (Note: As of 2024/7/16, it has not been merged into the main branch)"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"coqui-tts-local-deployment",children:"Coqui-TTS (Local Deployment)"}),"\n",(0,l.jsx)(n.p,{children:"Coqui-TTS is an open-source speech synthesis toolkit that supports multiple models and languages. The inference speed depends on the size and complexity of the chosen model."}),"\n",(0,l.jsx)(n.h3,{id:"installation-steps-1",children:"Installation Steps"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sh",children:'# Install Coqui-TTS and its language support\nuv pip install "coqui-tts[languages]"\n'})}),"\n",(0,l.jsx)(n.h3,{id:"model-configuration",children:"Model Configuration"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"View available models:"}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sh",children:"uv run tts --list_models\n"})}),"\n",(0,l.jsxs)(n.ol,{start:"2",children:["\n",(0,l.jsxs)(n.li,{children:["Configure in ",(0,l.jsx)(n.code,{children:"conf.yaml"}),":"]}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-yaml",children:' coqui_tts:\n      # Name of the TTS model to use. If empty, the default model will be used\n      # Run "tts --list_models" to list models supported by coqui-tts\n      # Some examples:\n      # - "tts_models/en/ljspeech/tacotron2-DDC" (single speaker)\n      # - "tts_models/zh-CN/baker/tacotron2-DDC-GST" (Chinese single speaker)\n      # - "tts_models/multilingual/multi-dataset/your_tts" (multi-speaker)\n      # - "tts_models/multilingual/multi-dataset/xtts_v2" (multi-speaker)\n      model_name: "tts_models/en/ljspeech/tacotron2-DDC" # Model name\n      speaker_wav: "" # Path to reference audio file\n      language: "en" # Language\n      device: "" # Device\n'})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Single Language Models"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Default configuration is for English single language model"}),"\n",(0,l.jsxs)(n.li,{children:["For Chinese support, please change to a Chinese model (e.g., ",(0,l.jsx)(n.code,{children:"tts_models/zh-CN/baker/tacotron2-DDC-GST"}),")"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Multilingual Models"}),":"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"speaker_wav"}),": Path to reference audio file","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Supports relative paths (e.g., ",(0,l.jsx)(n.code,{children:"./voices/reference.wav"}),")"]}),"\n",(0,l.jsxs)(n.li,{children:["For Windows, when using absolute paths, change ",(0,l.jsx)(n.code,{children:"\\"})," to ",(0,l.jsx)(n.code,{children:"\\\\"})]}),"\n",(0,l.jsx)(n.li,{children:"Ensure the reference audio file exists at the specified location"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"language"}),": Set the preferred language","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Set to ",(0,l.jsx)(n.code,{children:'"zh"'})," for Chinese"]}),"\n",(0,l.jsxs)(n.li,{children:["Set to ",(0,l.jsx)(n.code,{children:'"en"'})," for English"]}),"\n",(0,l.jsxs)(n.li,{children:["This parameter corresponds to ",(0,l.jsx)(n.code,{children:"speaker_wav"})]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"gptsovits-local-deployment-moderate-performance",children:"GPTSoVITS (Local Deployment, Moderate Performance)"}),"\n",(0,l.jsxs)(n.blockquote,{children:["\n",(0,l.jsxs)(n.p,{children:["Introduced in ",(0,l.jsx)(n.a,{href:"https://github.com/t41372/Open-LLM-VTuber/pull/40",children:"PR #40"}),", officially released in version v0.4.0"]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"GPT-SoVITS is a powerful speech synthesis engine capable of high-quality voice cloning."}),"\n",(0,l.jsxs)(n.admonition,{type:"note",children:[(0,l.jsxs)(n.p,{children:["Some of the following content is compiled from the ",(0,l.jsx)(n.a,{href:"https://docs.qq.com/doc/DTHR6WkZ3aU9JcXpy",children:"Tencent Document"})," in the QQ group"]}),(0,l.jsx)(n.p,{children:"The official tutorial for GPTSoVITS is currently incomplete, you can refer to the Tencent Document for deployment."})]}),"\n",(0,l.jsx)(n.h3,{id:"gptsovits-v2-integration-package",children:(0,l.jsx)(n.a,{href:"https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e/dkxgpiy9zb96hob4#KTvnO",children:"GPTSoVITS-V2 Integration Package"})}),"\n",(0,l.jsx)(n.h3,{id:"mihoyo-one-click-package",children:(0,l.jsx)(n.a,{href:"https://www.bilibili.com/video/BV1D7421R7Rn",children:"miHoYo One-Click Package"})}),"\n",(0,l.jsx)(n.h2,{id:"bark-local-deployment-relatively-slow",children:"Bark (Local Deployment, Relatively Slow)"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Install dependencies:","\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sh",children:"uv pip install git+https://github.com/suno-ai/bark.git\n"})}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["Set ",(0,l.jsx)(n.code,{children:"tts_model: bark_tts"})," in ",(0,l.jsx)(n.code,{children:"conf.yaml"})]}),"\n",(0,l.jsx)(n.li,{children:"Required models will be automatically downloaded on first launch"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"cosyvoice-tts-local-deployment-relatively-slow",children:"CosyVoice TTS (Local Deployment, Relatively Slow)"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Configure and start the WebUI according to the ",(0,l.jsx)(n.a,{href:"https://github.com/FunAudioLLM/CosyVoice",children:"CosyVoice official documentation"})]}),"\n",(0,l.jsxs)(n.li,{children:["Refer to the API documentation in the WebUI and configure accordingly in the ",(0,l.jsx)(n.code,{children:"cosyvoiceTTS"})," section of ",(0,l.jsx)(n.code,{children:"conf.yaml"})]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"x-tts-local-deployment-relatively-slow",children:"X-TTS (Local Deployment, Relatively Slow)"}),"\n",(0,l.jsxs)(n.blockquote,{children:["\n",(0,l.jsxs)(n.p,{children:["Available since version ",(0,l.jsx)(n.code,{children:"v0.2.4"})," (",(0,l.jsx)(n.a,{href:"https://github.com/t41372/Open-LLM-VTuber/pull/23",children:"PR#23"}),")"]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"It is recommended to use xtts-api-server, which provides clear API documentation and is relatively easy to deploy."}),"\n",(0,l.jsx)(n.h2,{id:"edge-tts-online-no-api-key-required",children:"Edge TTS (Online, No API Key Required)"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Features:","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Fast response speed"}),"\n",(0,l.jsx)(n.li,{children:"Requires maintaining network connection"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["Configuration: Set ",(0,l.jsx)(n.code,{children:"tts_model: edge_tts"})," in ",(0,l.jsx)(n.code,{children:"conf.yaml"})]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"fish-audio-tts-online-api-key-required",children:"Fish Audio TTS (Online, API Key Required)"}),"\n",(0,l.jsxs)(n.blockquote,{children:["\n",(0,l.jsxs)(n.p,{children:["Available since version ",(0,l.jsx)(n.code,{children:"v0.3.0-beta"})]}),"\n"]}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Install dependencies:"}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-sh",children:"uv pip install fish-audio-sdk\n"})}),"\n",(0,l.jsxs)(n.ol,{start:"2",children:["\n",(0,l.jsxs)(n.li,{children:["Configuration steps:","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["Register an account on ",(0,l.jsx)(n.a,{href:"https://fish.audio/",children:"Fish Audio"})," and obtain an API key"]}),"\n",(0,l.jsx)(n.li,{children:"Select the desired voice and copy its Reference ID"}),"\n",(0,l.jsxs)(n.li,{children:["In ",(0,l.jsx)(n.code,{children:"conf.yaml"}),", set:","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"tts_model: fish_api_tts"})}),"\n",(0,l.jsxs)(n.li,{children:["Fill in ",(0,l.jsx)(n.code,{children:"api_key"})," and ",(0,l.jsx)(n.code,{children:"reference_id"})," in the ",(0,l.jsx)(n.code,{children:"fish_api_tts"})," section"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"azure-tts-online-api-key-required",children:"Azure TTS (Online, API Key Required)"}),"\n",(0,l.jsxs)(n.blockquote,{children:["\n",(0,l.jsx)(n.p,{children:"The same TTS service as neuro-sama"}),"\n"]}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Obtain an API key for the text-to-speech service from Azure"}),"\n",(0,l.jsxs)(n.li,{children:["Fill in the relevant configuration in the ",(0,l.jsx)(n.code,{children:"azure_tts"})," section of ",(0,l.jsx)(n.code,{children:"conf.yaml"})]}),"\n"]}),"\n",(0,l.jsx)(n.admonition,{type:"warning",children:(0,l.jsxs)(n.p,{children:["Since version ",(0,l.jsx)(n.code,{children:"v0.2.5"}),", ",(0,l.jsx)(n.code,{children:"api_key.py"})," has been deprecated. Please make sure to set the API key in ",(0,l.jsx)(n.code,{children:"conf.yaml"})]})}),"\n",(0,l.jsx)(n.admonition,{type:"tip",children:(0,l.jsxs)(n.p,{children:["The default voice used in ",(0,l.jsx)(n.code,{children:"conf.yaml"})," is the same as neuro-sama"]})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(a,{...e})}):a(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>d});var s=i(6540);const l={},t=s.createContext(l);function o(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:o(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);